{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MorphologicalClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb7ZbOVFLycw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Piyjea55QU-9"
      },
      "source": [
        "%cd drive/MyDrive/Security_copy/Andres2Windows/Andres/Advance_compuation/Project3/\n",
        "# !tar -xvf fastai-datasets-kaggle-galaxy-zoo-the-galaxy-challenge-1.tar\n",
        "# !ls images_training_rev1/\n",
        "# !ls images_test_rev1/\n",
        "# !tar -xzvf images_training_rev1.tar.gz\n",
        "# !pwd\n",
        "# !ls images_training_rev1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L4WQNN9MN1u"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# This is to run here in my pc\n",
        "# import os\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "def append_ext(filename):\n",
        "    return filename + \".jpg\"\n",
        "\n",
        "\n",
        "def Wrapper1ImageDataGenerator():\n",
        "    \"\"\"\n",
        "    fill_mode: is set to nearest, this have physical sense. For instance, in\n",
        "      the case of a well centered galaxy, it will fill the points outside the\n",
        "      boundaries of the input image with the same color of the background.\n",
        "    rescale: set to 1/255 to have values of image between 0 an 255.\n",
        "    rotation: any number as the morpholgy and such things are not really\n",
        "      affected by it (180 means between -180 and 180).\n",
        "    shifts: invariance in shifts is also used but not as strongly since\n",
        "      sometimes images are very near the border.\n",
        "    flips: similar to rotations\n",
        "    validation_split: set to 0.2 to follow normal standarts of the percent of\n",
        "      validation data.\n",
        "    \"\"\"\n",
        "    datagen = ImageDataGenerator(\n",
        "        fill_mode='nearest',\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        validation_split=0.2)\n",
        "\n",
        "    return datagen\n",
        "\n",
        "\n",
        "def Wrapper1DataGenerator(dict_params):\n",
        "    \"\"\"\n",
        "    class_mode: is set to raw since the results given are simply numerical with\n",
        "      the belong probabilities to each class.\n",
        "    batch_size: set to 2 multiple supposing this will give better preformance\n",
        "    \"\"\"\n",
        "    train_generator = dict_params[\"data_generator\"].flow_from_dataframe(\n",
        "        dataframe=dict_params[\"dataframe\"],\n",
        "        directory=dict_params[\"directory\"],\n",
        "        x_col=\"id\",\n",
        "        y_col=classes,\n",
        "        subset=dict_params[\"subset_name\"],\n",
        "        batch_size=64,\n",
        "        seed=123,\n",
        "        shuffle=True,\n",
        "        class_mode=\"raw\",\n",
        "        target_size=(224, 224))\n",
        "\n",
        "    return train_generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQrHKWBlMRGc"
      },
      "source": [
        "classes = ['Class1.1', 'Class1.2', 'Class1.3', 'Class2.1', 'Class2.2',\n",
        "           'Class3.1', 'Class3.2', 'Class4.1', 'Class4.2', 'Class5.1',\n",
        "           'Class5.2', 'Class5.3', 'Class5.4', 'Class6.1', 'Class6.2',\n",
        "           'Class7.1', 'Class7.2', 'Class7.3', 'Class8.1', 'Class8.2',\n",
        "           'Class8.3', 'Class8.4', 'Class8.5', 'Class8.6', 'Class8.7',\n",
        "           'Class9.1', 'Class9.2', 'Class9.3', 'Class10.1', 'Class10.2',\n",
        "           'Class10.3', 'Class11.1', 'Class11.2', 'Class11.3', 'Class11.4',\n",
        "           'Class11.5', 'Class11.6']\n",
        "\n",
        "# This will read the probability results for each galaxy into the different\n",
        "#   classes.\n",
        "traindf = pd.read_csv('training_solutions_rev1.csv')\n",
        "\n",
        "# Creating a new column with \"GalaxyID\" + \"jpg\", so that our image name matches\n",
        "#   to this new column in the data-frame/csv.\n",
        "traindf[\"id\"] = traindf['GalaxyID'].astype(str).apply(append_ext)\n",
        "\n",
        "# Create generator object with given augmentation and strcuture.\n",
        "# specify suitables augmentations\n",
        "datagen = Wrapper1ImageDataGenerator()\n",
        "# specify the general structure of chunks to be trained and its generator\n",
        "params = {\"dataframe\": traindf, \"data_generator\": datagen,\n",
        "          \"subset_name\": \"training\", \"directory\": \"images_training_rev2\"}\n",
        "train_generator = Wrapper1DataGenerator(params)\n",
        "# structure of validation gen and itself.\n",
        "params[\"subset_name\"] = \"validation\"\n",
        "valid_generator = Wrapper1DataGenerator(params)\n",
        "\n",
        "# # This somewhat garantees that it will pass through the batch that constain all\n",
        "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
        "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvSI3kw0tzAn"
      },
      "source": [
        "Then, we use Resnet:\n",
        "\n",
        "ResNet-50 is a convolutional neural network that is trained on more than a million images from the ImageNet database [1]. The network is 50 layers deep and can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOPGEO9lszvq",
        "outputId": "5eb052fd-e547-4823-c739-7c16f3667748"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Modify last layer of the model in order to do the classification\n",
        "img_shape = (224, 224, 3)\n",
        "resnet_model = ResNet50(include_top=False, input_shape=img_shape)\n",
        "# flatten output of last layer before adding output layer (Dense layer)\n",
        "x = Flatten()(resnet_model.output)  # This will Flatten the reset_model output\n",
        "# add output layer (number of outputs = 37)\n",
        "x = Dense(len(classes), activation='sigmoid')(x)\n",
        "# load the modified model\n",
        "model = Model(inputs=resnet_model.input, outputs=x)\n",
        "\n",
        "# In order to obtain better results we set them all to trainable\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001, decay=5e-4)\n",
        "\n",
        "# The mean squared error is used for the tranining, and accuracy gives the\n",
        "#   number of correct predictions.\n",
        "model.compile(optimizer, loss='mse', metrics=[\"accuracy\"])\n",
        "\n",
        "# The callbaks are used to save the values of the current state in the training\n",
        "\n",
        "# Class to sabe the losses in training and validation\n",
        "class LossHistory(Callback):\n",
        "  def on_train_begin(self, logs={}):\n",
        "      self.losses = []\n",
        "      self.val_losses = []\n",
        "\n",
        "  def on_batch_end(self, batch, logs={}):\n",
        "          self.losses.append(logs.get('loss'))\n",
        "          self.val_losses.append(logs.get('val_loss'))\n",
        "\n",
        "history = LossHistory()\n",
        "\n",
        "# make the algorithm stop if there is not improvement, it is assumed taht 4 \n",
        "#   epochs with not improvement will not give better results\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "class CheckPointCallBacks(tf.keras.callbacks.ModelCheckpoint):\n",
        "    def __init__(self, filepath, verbose, save_best_only, init_epoch):\n",
        "        super().__init__(filepath=filepath, verbose=verbose, \n",
        "                         save_best_only=save_best_only)\n",
        "        self.effective_epoch = init_epoch\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.effective_epoch += 1\n",
        "        self.filepath = \"train_param/weights-improvement-%02d-{val_accuracy:.2f}.hdf5\" % (self.effective_epoch)\n",
        "\n",
        "\n",
        "actual_epoch = 10\n",
        "filepath = \"train_param/weights-improvement-10-0.76.hdf5\"\n",
        "model = load_model(\"train_param/weights-improvement-10-0.76.hdf5\")\n",
        "checkpointer = CheckPointCallBacks(filepath=filepath, verbose=2, \n",
        "                                  save_best_only=True, \n",
        "                                  init_epoch=actual_epoch)\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(filepath.format(epoch=30))\n",
        "\n",
        "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "# checkpointer = ModelCheckpoint(filepath=filepath, verbose=2, save_best_only=True)\n",
        "\n",
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=STEP_SIZE_VALID,\n",
        "    epochs=30,\n",
        "    callbacks=[history, checkpointer, early_stopping])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "769/769 [==============================] - 19836s 26s/step - loss: 0.0103 - accuracy: 0.7716 - val_loss: 0.0104 - val_accuracy: 0.7603\n",
            "Epoch 2/30\n",
            "769/769 [==============================] - 977s 1s/step - loss: 0.0104 - accuracy: 0.7705 - val_loss: 0.0146 - val_accuracy: 0.7274\n",
            "Epoch 3/30\n",
            "769/769 [==============================] - 959s 1s/step - loss: 0.0102 - accuracy: 0.7759 - val_loss: 0.0106 - val_accuracy: 0.7739\n",
            "Epoch 4/30\n",
            "769/769 [==============================] - 961s 1s/step - loss: 0.0100 - accuracy: 0.7754 - val_loss: 0.0099 - val_accuracy: 0.7685\n",
            "Epoch 5/30\n",
            "769/769 [==============================] - 997s 1s/step - loss: 0.0097 - accuracy: 0.7795 - val_loss: 0.0096 - val_accuracy: 0.7689\n",
            "Epoch 6/30\n",
            "769/769 [==============================] - 1012s 1s/step - loss: 0.0094 - accuracy: 0.7823 - val_loss: 0.0094 - val_accuracy: 0.7770\n",
            "Epoch 7/30\n",
            "769/769 [==============================] - 975s 1s/step - loss: 0.0092 - accuracy: 0.7815 - val_loss: 0.0087 - val_accuracy: 0.7849\n",
            "Epoch 8/30\n",
            "769/769 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.7828"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phWrgrIqvnuS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(hist.epoch, hist.history['loss'], label='Training Loss')\n",
        "plt.plot(hist.epoch, hist.history['val_loss'], label='Validation', linestyle='--')\n",
        "plt.title(\"RMSE vs Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.legend()\n",
        "plt.savefig(\"TrainingResult2.png\")\n",
        "plt.show()\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1X3etDFzAGX"
      },
      "source": [
        "# Load best result obtained\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"train_param/weights-improvement-10-0.76.hdf5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYa5UErFcisS"
      },
      "source": [
        "model.predict_generator(train_generator, steps=train_generator.n / train_generator.batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCb1btbmiRLI"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxp-lHkmQUST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oB5_hu9Qrny"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}